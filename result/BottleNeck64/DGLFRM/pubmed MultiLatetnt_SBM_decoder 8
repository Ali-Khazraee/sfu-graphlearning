Using backend: pytorch
VGAE FRAMEWORK SETING: Namespace(DropOut_rate=0.3, Vis_step=180, batch_norm=True, dataset='pubmed', decoder_type='MultiLatetnt_SBM_decoder', edge_type_visulizer=True, encoder_layers='64', encoder_type='mixture_of_GCNs', epoch_number=200, lr=0.001, mpath='VGAE_FrameWork_MODEL', negative_sampling_rate=1, num_node=-1, num_of_comunities=64, num_of_relations=8, save_embeddings_to_file=False, split_the_data_to_train_test=True, use_feature=True)
GVAE_FrameWork(
  (decoder): MultiLatetnt_SBM_decoder(
    (nodeTransformer): ModuleList(
      (0): node_mlp(
        (layers): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): Linear(in_features=32, out_features=64, bias=True)
        )
        (norm_layers): ModuleList(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (1): node_mlp(
        (layers): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): Linear(in_features=32, out_features=64, bias=True)
        )
        (norm_layers): ModuleList(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (2): node_mlp(
        (layers): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): Linear(in_features=32, out_features=64, bias=True)
        )
        (norm_layers): ModuleList(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (3): node_mlp(
        (layers): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): Linear(in_features=32, out_features=64, bias=True)
        )
        (norm_layers): ModuleList(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (4): node_mlp(
        (layers): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): Linear(in_features=32, out_features=64, bias=True)
        )
        (norm_layers): ModuleList(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (5): node_mlp(
        (layers): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): Linear(in_features=32, out_features=64, bias=True)
        )
        (norm_layers): ModuleList(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (6): node_mlp(
        (layers): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): Linear(in_features=32, out_features=64, bias=True)
        )
        (norm_layers): ModuleList(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (7): node_mlp(
        (layers): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): Linear(in_features=32, out_features=64, bias=True)
        )
        (norm_layers): ModuleList(
          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
    )
    (lambdas): ParameterList(
        (0): Parameter containing: [torch.FloatTensor of size 64x64]
        (1): Parameter containing: [torch.FloatTensor of size 64x64]
        (2): Parameter containing: [torch.FloatTensor of size 64x64]
        (3): Parameter containing: [torch.FloatTensor of size 64x64]
        (4): Parameter containing: [torch.FloatTensor of size 64x64]
        (5): Parameter containing: [torch.FloatTensor of size 64x64]
        (6): Parameter containing: [torch.FloatTensor of size 64x64]
        (7): Parameter containing: [torch.FloatTensor of size 64x64]
    )
  )
  (encoder): mixture_of_GCNs(
    (gcns): ModuleList(
      (0): GCN(
        (ConvLayers): ModuleList(
          (0): GraphConv(in=500, out=64, normalization=both, activation=None)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (1): GCN(
        (ConvLayers): ModuleList(
          (0): GraphConv(in=500, out=64, normalization=both, activation=None)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (2): GCN(
        (ConvLayers): ModuleList(
          (0): GraphConv(in=500, out=64, normalization=both, activation=None)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (3): GCN(
        (ConvLayers): ModuleList(
          (0): GraphConv(in=500, out=64, normalization=both, activation=None)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (4): GCN(
        (ConvLayers): ModuleList(
          (0): GraphConv(in=500, out=64, normalization=both, activation=None)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (5): GCN(
        (ConvLayers): ModuleList(
          (0): GraphConv(in=500, out=64, normalization=both, activation=None)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (6): GCN(
        (ConvLayers): ModuleList(
          (0): GraphConv(in=500, out=64, normalization=both, activation=None)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
      (7): GCN(
        (ConvLayers): ModuleList(
          (0): GraphConv(in=500, out=64, normalization=both, activation=None)
        )
        (dropout): Dropout(p=0.3, inplace=False)
      )
    )
    (q_z_mean): GraphConv(in=512, out=64, normalization=both, activation=None)
    (q_z_std): GraphConv(in=512, out=64, normalization=both, activation=None)
  )
  (dropout): Dropout(p=0, inplace=False)
)
Val conf:
[[1126 1090]
 [1128 1088]]
Train Conf:
[[1094 1122]
 [1146 1070]]
Epoch: 001 | Loss: 2.365469 | Reconstruction_loss: 2.343640 | z_kl_loss: 0.021829 | Accuracy: 0.506070  | AUC:0.494517  | AP:0.514854
Val_acc: 0.499549 | Val_AUC: 0.501545 | Val_AP: 0.517464
